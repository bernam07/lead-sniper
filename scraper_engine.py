import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

def init_driver(headless=False):
    options = webdriver.ChromeOptions()
    if headless:
        options.add_argument("--headless")
    
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-blink-features=AutomationControlled") 
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    return driver

def get_detail_text(driver, type_data):
    """
    Fun√ß√£o auxiliar para encontrar texto dentro do painel de detalhes.
    Tenta v√°rias estrat√©gias para n√£o falhar.
    """
    try:
        if type_data == "phone":
            # Estrat√©gia 1: Bot√£o que tenha o aria-label a come√ßar por "Telefone:"
            try:
                btn = driver.find_element(By.CSS_SELECTOR, "button[aria-label*='Telefone:']")
                return btn.get_attribute("aria-label").replace("Telefone: ", "").strip()
            except:
                pass
            
            # Estrat√©gia 2: Bot√£o com √≠cone de telefone (data-item-id cont√©m 'phone')
            try:
                btn = driver.find_element(By.CSS_SELECTOR, "button[data-item-id*='phone']")
                return btn.get_attribute("aria-label").replace("Telefone: ", "").strip()
            except:
                return "N/A"

        elif type_data == "website":
            # Estrat√©gia 1: Bot√£o com data-item-id="authority" (Padr√£o do Google)
            try:
                btn = driver.find_element(By.CSS_SELECTOR, "a[data-item-id='authority']")
                return btn.get_attribute("href")
            except:
                return "N/A"
        
        elif type_data == "rating":
            try:
                # Procura o span que tem o role="img" e aria-label com "estrelas"
                span = driver.find_element(By.CSS_SELECTOR, "span[role='img'][aria-label*='estrelas']")
                return span.get_attribute("aria-label")
            except:
                return "N/A"

    except:
        return "N/A"
    return "N/A"

def run_scraper(search_query, max_results, headless=False):
    driver = init_driver(headless)
    results = []
    
    try:
        print("üåç A abrir Google Maps Oficial...")
        driver.get("https://www.google.com/maps?hl=pt-PT") 
        
        # --- COOKIES ---
        print("üç™ A tratar dos cookies...")
        try:
            wait = WebDriverWait(driver, 5)
            accept_btn = wait.until(EC.element_to_be_clickable((By.XPATH, "//button//span[contains(text(), 'Aceitar')]/..")))
            accept_btn.click()
            time.sleep(2) 
        except:
            pass

        # --- PESQUISA ---
        print(f"üîé A pesquisar por: {search_query}")
        try:
            wait = WebDriverWait(driver, 10)
            input_box = wait.until(EC.presence_of_element_located((By.ID, "searchboxinput")))
        except:
            input_box = driver.find_element(By.TAG_NAME, "input")

        input_box.clear()
        input_box.send_keys(search_query)
        time.sleep(0.5)
        input_box.send_keys(Keys.ENTER)
        print("‚úÖ Pesquisa enviada. A carregar lista...")
        time.sleep(5) 

        # --- EXTRA√á√ÉO PROFUNDA ---
        scraped_ids = set()
        
        while len(results) < max_results:
            # Encontra todos os cart√µes de neg√≥cio na lista
            elements = driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']")
            valid_elements = [el for el in elements if el.get_attribute("aria-label")]
            
            if not valid_elements:
                print("‚è≥ A carregar mais...")
                time.sleep(2)
            
            found_new = False
            
            for index, el in enumerate(valid_elements):
                if len(results) >= max_results:
                    break
                
                try:
                    link = el.get_attribute("href")
                    name = el.get_attribute("aria-label")
                    
                    if link in scraped_ids:
                        continue
                    
                    found_new = True
                    scraped_ids.add(link)
                    
                    # --- O TRUQUE: CLICAR NO ELEMENTO ---
                    # Fazemos scroll at√© ele para garantir que √© clic√°vel
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", el)
                    time.sleep(1)
                    el.click()
                    
                    # Espera o painel lateral carregar os detalhes (Telefone/Site)
                    time.sleep(2.5) 
                    
                    # Extrair Dados
                    phone = get_detail_text(driver, "phone")
                    website = get_detail_text(driver, "website")
                    rating = get_detail_text(driver, "rating")
                    
                    print(f"üìç [{len(results)+1}] {name} | üìû {phone} | üåê {website}")
                    
                    results.append({
                        "Business Name": name,
                        "Phone": phone,
                        "Website": website,
                        "Rating": rating,
                        "Maps Link": link
                    })
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Erro ao processar item: {e}")
                    continue

            # Se cheg√°mos ao fundo dos vis√≠veis, fazer scroll na lista
            try:
                if valid_elements:
                    driver.execute_script("arguments[0].scrollIntoView();", valid_elements[-1])
                else:
                    driver.find_element(By.CSS_SELECTOR, "div[role='feed']").send_keys(Keys.PAGE_DOWN)
            except:
                pass
                
            time.sleep(2)

            if not found_new and len(results) > 0:
                # Tenta esperar um pouco mais
                time.sleep(2)
                check = driver.find_elements(By.CSS_SELECTOR, "a[href*='/maps/place/']")
                if len(check) == len(elements):
                    print("‚èπÔ∏è Fim da lista.")
                    break

    except Exception as e:
        print(f"‚ùå Erro: {e}")
        driver.save_screenshot("erro_scraper.png")
    finally:
        driver.quit()
        
    return results